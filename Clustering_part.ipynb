{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the “ShiMuTian Community” regional data from the data\n",
    "with open('/home/zju/xlc/bert/bert-master/addressData/realFinal/final_cluster_500semantic30%.txt', 'r') as f01，open('/home/zju/xlc/bert/bert-master/addressData/final_right.txt', 'r') as f02,open('/home/zju/xlc/bert/bert-master/addressData/realFinal/final_cluster_500semantic40%_allInfo.csv', 'w') as f03:\n",
    "    line1 = f01.readlines()\n",
    "    line2 = f02.readlines()\n",
    "    for i in range(len(line1)):\n",
    "        if line2[i].split(',')[6] == \"十亩田社区\" :\n",
    "            f03.writelines(line2[i].strip('\\n') + line1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/zju/xlc/bert/bert-master/addressData/realFinal/final_cluster_500semantic30%.txt','r') as f01,open('/home/zju/xlc/bert/bert-master/addressData/final_right.txt','r') as f02,open('/home/zju/xlc/bert/bert-master/addressData/realFinal/final_cluster_500semantic30%_allInfo.csv','w') as f03:\n",
    "    line1 = f01.readlines()\n",
    "    line2 = f02.readlines()\n",
    "    for i in range(len(line1)):\n",
    "        if line2[i].split(',')[6] == \"十亩田社区\" :\n",
    "            f03.writelines(line2[i].strip('\\n') + ',' + line1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "\n",
    "a = loadtxt('/home/zju/xlc/bert/bert-master/addressData/final_onlyLonLat.txt')\n",
    "print(a.max(axis=0))\n",
    "print(a.min(axis=0))\n",
    "# print(sqrt(sum(square(a.max(axis=0) - a.min(axis=0)))))\n",
    "b = loadtxt('/home/zju/xlc/bert/bert-master/addressData/finalDataSentanceVec.txt')\n",
    "# print(sqrt(sum(square(b.max(axis=0) - b.min(axis=0)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatial features and semantic concatenation\n",
    "weight = 886.5 #weight set\n",
    "lonWeight = weight * a\n",
    "concatResult = append(lonWeight, b, axis=1) \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "result = np.loadtxt('/home/zju/xlc/bert/bert-master/addressData/realFinal/final_cluster_500semantic40%.txt')\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do Dimensionality reduction using PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "\n",
    "pca = decomposition.PCA(n_components=3)\n",
    "pca.fit(vecList)\n",
    "X = pca.transform(vecList)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(12.8, 9.6))\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=result, cmap='tab20', alpha=0.5, s=0.5)\n",
    "# ax.savefig(\"0305-6-4-500-pca.png\")\n",
    "# ax.colorbar()\n",
    "ax.view_init(elev=30,azim=300)\n",
    "ax.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering based on the K-means\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "mbk = MiniBatchKMeans( n_clusters=500,init='k-means++',batch_size=200000,n_init=10)\n",
    "\n",
    "mbk.fit(concatResult)\n",
    "colorArray = ['k', 'brown']\n",
    "result = mbk.predict(concatResult)\n",
    "with open('../../SheQuData/forClassifier_spatial.tsv', 'w', encoding='UTF-8') as fClassifier:\n",
    "    addressDarray = loadtxt('../../SheQuData/Address_By_Shequ_Format4train.tsv', dtype='str', usecols=(1))\n",
    "    for li in range(len(linesSpatial)):\n",
    "        fClassifier.writelines(str(result[li]) + '\\t' + str(addressDarray[li]) + '\\n')\n",
    "\n",
    "lat = []\n",
    "lon = []\n",
    "for l in range(a.shape[0]):\n",
    "    lon.append(float(a[l,0]))\n",
    "    lat.append(float(a[l,1]))\n",
    "with open('../../SheQuData/label.txt', 'w') as fb:\n",
    "    for j in range(len(result)):\n",
    "        fb.writelines(result[j])\n",
    "\n",
    "plt.rcParams['savefig.dpi'] = 600 \n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "#c=colors[index] colors = ['b','g','r','orange']\n",
    "plt.scatter(lon, lat, c=result,  alpha=0.5, cmap='tab20', s=5, marker=\"X\")\n",
    "plt.savefig(\"0305-6-4-500.png\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import pandas as pd\n",
    "lat = []\n",
    "lon = []\n",
    "for l in range(a.shape[0]):\n",
    "    lon.append(float(a[l,0]))\n",
    "    lat.append(float(a[l,1]))\n",
    "with open('../../SheQuData/label.txt', 'w') as fb:\n",
    "    for j in range(len(result)):\n",
    "        fb.writelines(result[j])\n",
    "\n",
    "plt.rcParams['savefig.dpi'] = 600 \n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "#c=colors[index] colors = ['b','g','r','orange']\n",
    "plt.scatter(lon, lat, c=result,  alpha=0.5, cmap='tab20', s=5, marker=\"X\")\n",
    "plt.savefig(\"0305-6-4-500.png\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/zju/xlc/bert/bert-master/addressData/realFinal/final_cluster_500semantic60%.txt', 'w') as fff:\n",
    "    for j in range(result.shape[0]):\n",
    "        fff.writelines(str(result[j])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/zju/xlc/bert/bert-master/addressData/realFinal/final_cluster_500semantic60%.txt', 'r') as f01, open('/home/zju/xlc/bert/bert-master/addressData/finalData.txt','r') as f02, open('/home/zju/xlc/bert/bert-master/addressData/classifierData/realFinal/500semantic60%classifierDataset_spatial.tsv','w') as f03:\n",
    "    lines1 = f01.readlines()\n",
    "    lines2 = f02.readlines()\n",
    "    print(len(lines1))\n",
    "    print(len(lines2))\n",
    "    for i in range(len(lines1)):\n",
    "        f03.writelines(lines1[i].strip('\\n') + '\\t' + lines2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import pandas as pd\n",
    "\n",
    "def toColor(result):\n",
    "    colorSeries={\n",
    "\n",
    "    }\n",
    "    return result\n",
    "\n",
    "#minibatch做融合聚类\n",
    "# with open('/home/zju/xlc/bert/bert-master/addressData/finalDataSentanceVec.txt', 'r', encoding='UTF-8') as fa:\n",
    "#     linesSpatial = fa.readlines()\n",
    "lonLat = loadtxt(\"/home/zju/xlc/bert/bert-master/addressData/final_onlyLonLat.txt\")\n",
    "weightNum = 1379 #权重参数,591为50%\n",
    "lonLatWeighted = lonLat * weightNum\n",
    "\n",
    "#测试\n",
    "print(lonLat.shape[0])\n",
    "print(float(lonLat[1,0]))\n",
    "print(float(lonLat[1,1]))\n",
    "\n",
    "sentanceVec = loadtxt(\"/home/zju/xlc/bert/bert-master/addressData/finalDataSentanceVec.txt\")\n",
    "\n",
    "vecList = append(lonLatWeighted, sentanceVec, axis=1) #将加权经纬度与词向量做连接\n",
    "print('done')\n",
    "\n",
    "mbk = KMeans( n_clusters=500,init='k-means++',n_init=10, algorithm='elkan')\n",
    "\n",
    "mbk.fit(vecList)\n",
    "colorArray = ['k', 'brown']\n",
    "result = mbk.predict(vecList)\n",
    "# with open('../../SheQuData/forClassifier_spatial.tsv', 'w', encoding='UTF-8') as fClassifier:\n",
    "#     addressDarray = loadtxt('../../SheQuData/Address_By_Shequ_Format4train.tsv', dtype='str', usecols=(1))\n",
    "#     for li in range(len(linesSpatial)):\n",
    "#         fClassifier.writelines(str(result[li]) + '\\t' + str(addressDarray[li]) + '\\n')\n",
    "\n",
    "lat = []\n",
    "lon = []\n",
    "for l in range(lonLat.shape[0]):\n",
    "    lon.append(float(lonLat[l,0]))\n",
    "    lat.append(float(lonLat[l,1]))\n",
    "# with open('../../SheQuData/label.txt', 'w') as fb:\n",
    "#     for j in range(len(result)):\n",
    "#         fb.writelines(result[j])\n",
    "\n",
    "plt.rcParams['savefig.dpi'] = 600 #图片像素\n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "plt.scatter(lon, lat, c=result,  alpha=0.5, cmap='tab20', s=5, marker=\"X\")\n",
    "plt.savefig(\"justForTest80.png\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "mbk = MiniBatchKMeans( n_clusters=500,init='k-means++',batch_size=200000,n_init=10)\n",
    "\n",
    "mbk.fit(vecList)\n",
    "colorArray = ['k', 'brown']\n",
    "result = mbk.predict(vecList)\n",
    "# with open('../../SheQuData/forClassifier_spatial.tsv', 'w', encoding='UTF-8') as fClassifier:\n",
    "#     addressDarray = loadtxt('../../SheQuData/Address_By_Shequ_Format4train.tsv', dtype='str', usecols=(1))\n",
    "#     for li in range(len(linesSpatial)):\n",
    "#         fClassifier.writelines(str(result[li]) + '\\t' + str(addressDarray[li]) + '\\n')\n",
    "\n",
    "lat = []\n",
    "lon = []\n",
    "for l in range(lonLat.shape[0]):\n",
    "    lon.append(float(lonLat[l,0]))\n",
    "    lat.append(float(lonLat[l,1]))\n",
    "# with open('../../SheQuData/label.txt', 'w') as fb:\n",
    "#     for j in range(len(result)):\n",
    "#         fb.writelines(result[j])\n",
    "\n",
    "plt.rcParams['savefig.dpi'] = 600 #图片像素\n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "#c=colors[index] colors = ['b','g','r','orange']\n",
    "plt.scatter(lon, lat, c=result,  alpha=0.5, cmap='tab20', s=5, marker=\"X\")\n",
    "plt.savefig(\"0404-7-3-500.png\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/zju/xlc/bert/bert-master/addressData/realFinal/final_cluster_500semantic30%.txt', 'w') as fff:\n",
    "    for j in range(result.shape[0]):\n",
    "        fff.writelines(str(result[j])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/zju/xlc/bert/bert-master/addressData/realFinal/final_cluster_500semantic30%.txt', 'r') as f01, open('/home/zju/xlc/bert/bert-master/addressData/finalData.txt','r') as f02, open('/home/zju/xlc/bert/bert-master/addressData/classifierData/realFinal/500semantic30%classifierDataset_spatial.tsv','w') as f03:\n",
    "    lines1 = f01.readlines()\n",
    "    lines2 = f02.readlines()\n",
    "    print(len(lines1))\n",
    "    print(len(lines2))\n",
    "    for i in range(len(lines1)):\n",
    "        f03.writelines(lines1[i].strip('\\n') + '\\t' + lines2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这是五五开的情况\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "mbk = MiniBatchKMeans( n_clusters=500,init='k-means++',batch_size=200000,n_init=10)\n",
    "\n",
    "mbk.fit(concatResult)\n",
    "colorArray = ['k', 'brown']\n",
    "result = mbk.predict(concatResult)\n",
    "# with open('../../SheQuData/forClassifier_spatial.tsv', 'w', encoding='UTF-8') as fClassifier:\n",
    "#     addressDarray = loadtxt('../../SheQuData/Address_By_Shequ_Format4train.tsv', dtype='str', usecols=(1))\n",
    "#     for li in range(len(linesSpatial)):\n",
    "#         fClassifier.writelines(str(result[li]) + '\\t' + str(addressDarray[li]) + '\\n')\n",
    "\n",
    "lat = []\n",
    "lon = []\n",
    "for l in range(a.shape[0]):\n",
    "    lon.append(float(a[l,0]))\n",
    "    lat.append(float(a[l,1]))\n",
    "# with open('../../SheQuData/label.txt', 'w') as fb:\n",
    "#     for j in range(len(result)):\n",
    "#         fb.writelines(result[j])\n",
    "\n",
    "plt.rcParams['savefig.dpi'] = 600 #图片像素\n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "#c=colors[index] colors = ['b','g','r','orange']\n",
    "plt.scatter(lon, lat, c=result,  alpha=0.5, cmap='tab20', s=5, marker=\"X\")\n",
    "plt.savefig(\"0304-5-5-500.png\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/zju/xlc/bert/bert-master/addressData/finalData/final_real_right_regress.tsv','r') as a1,open('/home/zju/xlc/bert/bert-master/addressData/finalData_w2vec.txt','r') as a2,open('/home/zju/xlc/bert/bert-master/addressData/finalData_w2vec_single.csv','w') as a3:\n",
    "    ll1 = a1.readlines()\n",
    "    ll2 = a2.readlines()\n",
    "    for i in range(len(ll1)):\n",
    "        a3.writelines(ll1[i].split('\\t')[1] + ',' +ll1[i].split('\\t')[2].strip('\\n') + ',' +ll2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import csv\n",
    "import os\n",
    "def _read_tsv(input_file, quotechar=None):\n",
    "    \"\"\"Reads a tab separated value file.\"\"\"\n",
    "    with tf.gfile.Open(input_file, \"r\") as f:\n",
    "      reader = csv.reader(f, delimiter=\",\", quotechar=quotechar)\n",
    "      lines = []\n",
    "      for line in reader:\n",
    "        lines.append(line)\n",
    "      return lines\n",
    "\n",
    "_read_tsv('/home/zju/xlc/bert/bert-master/addressData/finalData_w2vec_single.csv')\n",
    "print(lines[2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/zju/xlc/bert/bert-master/addressData/finalData_vec.txt','r') as ff1，open('/home/zju/xlc/bert/bert-master/addressData/finalData_vecOnly.txt','w') as ff2:\n",
    "    lin1 = ff1.readlines()\n",
    "    for l in range(len(lin1)):\n",
    "        ff2.writelines(lin1[i].strip(lin1[i].split('\\t')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/zju/xlc/bert/bert-master/addressData/finalData_vec.txt','r') as ff1,open('/home/zju/xlc/bert/bert-master/addressData/finalData_vecOnly.txt','w') as ff2:\n",
    "    lin1 = ff1.readlines()\n",
    "#     print(lin1[0].split(' ')[0])\n",
    "#     print(lin1[0].strip(lin1[0].split(' ')[0]))\n",
    "    for i in range(len(lin1)):\n",
    "        ff2.writelines(lin1[i].strip(lin1[i].split(' ')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "aa = loadtxt('/home/zju/xlc/bert/bert-master/addressData/finalData_vecOnly.txt')\n",
    "print(aa[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        with open('/home/zju/xlc/bert/bert-master/addressData/finalData_vec.txt','r') as ff1:\n",
    "            lin1 = ff1.readlines()\n",
    "            wordDict = {}\n",
    "            for l in range(len(lin1)):\n",
    "                wordDict[lin1[l].split(' ')[0]] = aa[l]\n",
    "        print(wordDict['江'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training set and validation set\n",
    "import random\n",
    "\n",
    "with open('/home/zju/xlc/bert/bert-master/addressData/finalData_w2vec_single.csv', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open('/home/zju/xlc/bert/bert-master/addressData/finalData/final_w2vec_real_right_regress_train.csv', 'w') as fa, open('/home/zju/xlc/bert/bert-master/addressData/finalData/final_w2vec_real_right_regress_eval.csv', 'w') as fb:\n",
    "    for _ in range(15000):\n",
    "        fb.write(lines.pop(random.randint(0, len(lines) - 1)))\n",
    "    fa.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/zju/xlc/bert/bert-master/addressData/realFinal/final_cluster_500semantic50%.txt', 'w') as fff:\n",
    "    for j in range(result.shape[0]):\n",
    "        fff.writelines(str(result[j])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/zju/xlc/bert/bert-master/addressData/realFinal/final_cluster_500semantic50%.txt', 'r') as f01, open('/home/zju/xlc/bert/bert-master/addressData/finalData.txt','r') as f02, open('/home/zju/xlc/bert/bert-master/addressData/classifierData/realFinal/500semantic50%classifierDataset_spatial.tsv','w') as f03:\n",
    "    lines1 = f01.readlines()\n",
    "    lines2 = f02.readlines()\n",
    "    print(len(lines1))\n",
    "    print(len(lines2))\n",
    "    for i in range(len(lines1)):\n",
    "        f03.writelines(lines1[i].strip('\\n') + '\\t' + lines2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/zju/xlc/bert/bert-master/addressData/classifierData/realFinal/500semantic50%classifierDataset_spatial.tsv', 'r') as f11, open('/home/zju/xlc/bert/bert-master/addressData/finalData/final_right_regress.tsv', 'r') as f12, open('/home/zju/xlc/bert/bert-master/addressData/finalData/final_real_right_regress.tsv', 'w') as f13:\n",
    "    line11 = f11.readlines()\n",
    "    line12 = f12.readlines()\n",
    "    line12.pop(0)\n",
    "    for i in range(len(line11)):\n",
    "        f13.writelines(line11[i].split('\\t')[1].strip('\\n') + '\\t' + line12[i].split('\\t')[1] + '\\t'+ line12[i].split('\\t')[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
